{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Convolutions for Images.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#6.2. Convolutions for Images\n","\n","From https://d2l.ai/chapter_convolutional-neural-networks/conv-layer.html using Pytorch"],"metadata":{"id":"MRF_nctpPF8M"}},{"cell_type":"code","source":["!pip install d2l"],"metadata":{"id":"WVG21xgUQrhU","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1642777963282,"user_tz":-480,"elapsed":21404,"user":{"displayName":"Hanif Kukuh Raharjo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gict81qvzCzYor7OD2HAqOMscBAGuRrSJShYazDZg=s64","userId":"02100760507760735849"}},"outputId":"6ed305c2-966b-4086-eabb-20414afd04fc"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting d2l\n","  Downloading d2l-0.17.3-py3-none-any.whl (82 kB)\n","\u001b[K     |████████████████████████████████| 82 kB 729 kB/s \n","\u001b[?25hCollecting matplotlib==3.3.3\n","  Downloading matplotlib-3.3.3-cp37-cp37m-manylinux1_x86_64.whl (11.6 MB)\n","\u001b[K     |████████████████████████████████| 11.6 MB 10.8 MB/s \n","\u001b[?25hCollecting numpy==1.18.5\n","  Downloading numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n","\u001b[K     |████████████████████████████████| 20.1 MB 98.8 MB/s \n","\u001b[?25hCollecting requests==2.25.1\n","  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n","\u001b[K     |████████████████████████████████| 61 kB 8.6 MB/s \n","\u001b[?25hRequirement already satisfied: jupyter==1.0.0 in /usr/local/lib/python3.7/dist-packages (from d2l) (1.0.0)\n","Collecting pandas==1.2.2\n","  Downloading pandas-1.2.2-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n","\u001b[K     |████████████████████████████████| 9.9 MB 51.7 MB/s \n","\u001b[?25hRequirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (5.6.1)\n","Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (5.2.2)\n","Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (5.2.0)\n","Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (5.3.1)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (4.10.1)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (7.6.5)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l) (2.8.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l) (7.1.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l) (3.0.6)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l) (1.3.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.2->d2l) (2018.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l) (2021.10.8)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l) (1.24.3)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l) (2.10)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib==3.3.3->d2l) (1.15.0)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.3.5)\n","Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.1.1)\n","Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.1.1)\n","Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.5.0)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (1.0.18)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (2.6.1)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (4.8.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (0.7.5)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (0.8.1)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (57.4.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (0.2.5)\n","Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (3.5.2)\n","Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (5.1.3)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (1.0.2)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (0.2.0)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (4.9.1)\n","Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (4.3.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (4.10.0)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (5.4.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (3.10.0.2)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (0.18.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (21.4.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (3.7.0)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l) (0.12.1)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l) (1.8.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l) (2.11.3)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter==1.0.0->d2l) (22.3.0)\n","Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter==1.0.0->d2l) (0.7.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter==1.0.0->d2l) (2.0.1)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (4.1.0)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.3)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (1.5.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.7.1)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.8.4)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.5.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter==1.0.0->d2l) (21.3)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter==1.0.0->d2l) (0.5.1)\n","Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter==1.0.0->d2l) (2.0.0)\n","Installing collected packages: numpy, requests, pandas, matplotlib, d2l\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.19.5\n","    Uninstalling numpy-1.19.5:\n","      Successfully uninstalled numpy-1.19.5\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 1.1.5\n","    Uninstalling pandas-1.1.5:\n","      Successfully uninstalled pandas-1.1.5\n","  Attempting uninstall: matplotlib\n","    Found existing installation: matplotlib 3.2.2\n","    Uninstalling matplotlib-3.2.2:\n","      Successfully uninstalled matplotlib-3.2.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 1.2.2 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.25.1 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed d2l-0.17.3 matplotlib-3.3.3 numpy-1.18.5 pandas-1.2.2 requests-2.25.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["matplotlib","mpl_toolkits","numpy","pandas"]}}},"metadata":{}}]},{"cell_type":"markdown","source":["6.2.1. The Cross-Correlation Operation\n","\n","Let us ignore channels for now and see how this works with two-dimensional data and hidden representations. The input is a two-dimensional tensor with a height of 3 and width of 3. We mark the shape of the tensor as  3×3  or ( 3 ,  3 ). The height and width of the kernel are both 2. The shape of the kernel window (or convolution window) is given by the height and width of the kernel (here it is  2×2 )."],"metadata":{"id":"51eaycvvQOh2"}},{"cell_type":"code","source":["import torch\n","from torch import nn\n","from d2l import torch as d2l\n","\n","def corr2d(X, K):  \n","    \"\"\"Compute 2D cross-correlation.\"\"\"\n","    h, w = K.shape\n","    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n","    for i in range(Y.shape[0]):\n","        for j in range(Y.shape[1]):\n","            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()\n","    return Y"],"metadata":{"id":"cIIrbJHiPQbC","executionInfo":{"status":"ok","timestamp":1642777968006,"user_tz":-480,"elapsed":4729,"user":{"displayName":"Hanif Kukuh Raharjo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gict81qvzCzYor7OD2HAqOMscBAGuRrSJShYazDZg=s64","userId":"02100760507760735849"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["We can construct the input tensor X and the kernel tensor K from Fig. 6.2.1 to validate the output of the above implementation of the two-dimensional cross-correlation operation."],"metadata":{"id":"4od7URbwQ8F8"}},{"cell_type":"code","source":["X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n","K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n","corr2d(X, K)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fZDj3IpePIl7","outputId":"a1c2d31f-5002-4993-8e53-532baa8ed393","executionInfo":{"status":"ok","timestamp":1642777968007,"user_tz":-480,"elapsed":22,"user":{"displayName":"Hanif Kukuh Raharjo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gict81qvzCzYor7OD2HAqOMscBAGuRrSJShYazDZg=s64","userId":"02100760507760735849"}}},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[19., 25.],\n","        [37., 43.]])"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["**6.2.2. Convolutional Layers**\n","\n","A convolutional layer cross-correlates the input and kernel and **adds a scalar bias **to produce an output. *The two parameters of a convolutional layer are the kernel and the scalar bias*. When training models based on convolutional layers, we typically initialize the kernels randomly, just as we would with a fully-connected layer.\n","\n","We are now ready to implement a two-dimensional convolutional layer based on the corr2d function defined above. In the __init__ constructor function, we declare weight and bias as the two model parameters. The forward propagation function calls the corr2d function and adds the bias."],"metadata":{"id":"pk2aG6zJRHXE"}},{"cell_type":"code","source":["class Conv2D(nn.Module):\n","    def __init__(self, kernel_size):\n","        super().__init__()\n","        self.weight = nn.Parameter(torch.rand(kernel_size))\n","        self.bias = nn.Parameter(torch.zeros(1))\n","\n","    def forward(self, x):\n","        return corr2d(x, self.weight) + self.bias"],"metadata":{"id":"oBSD2mEzRVRR","executionInfo":{"status":"ok","timestamp":1642777968008,"user_tz":-480,"elapsed":20,"user":{"displayName":"Hanif Kukuh Raharjo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gict81qvzCzYor7OD2HAqOMscBAGuRrSJShYazDZg=s64","userId":"02100760507760735849"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["**6.2.3. Object Edge Detection in Images**\n","\n","Let us take a moment to parse a simple application of a convolutional layer: detecting the edge of an object in an image by finding the location of the pixel change. First, we construct an “image” of  6×8  pixels. The middle four columns are black (0) and the rest are white (1)."],"metadata":{"id":"APwgF-rKRcvE"}},{"cell_type":"code","source":["X = torch.ones((6, 8))\n","X[:, 2:6] = 0\n","X"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PWnFg4T2Rgi8","outputId":"fa90a498-2efb-4bc1-ebe5-37b7e4cfa2b8","executionInfo":{"status":"ok","timestamp":1642777968009,"user_tz":-480,"elapsed":21,"user":{"displayName":"Hanif Kukuh Raharjo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gict81qvzCzYor7OD2HAqOMscBAGuRrSJShYazDZg=s64","userId":"02100760507760735849"}}},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n","        [1., 1., 0., 0., 0., 0., 1., 1.],\n","        [1., 1., 0., 0., 0., 0., 1., 1.],\n","        [1., 1., 0., 0., 0., 0., 1., 1.],\n","        [1., 1., 0., 0., 0., 0., 1., 1.],\n","        [1., 1., 0., 0., 0., 0., 1., 1.]])"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["Next, we construct a kernel K with a height of 1 and a width of 2. When we perform the cross-correlation operation with the input, if the horizontally adjacent elements are the same, the output is 0. Otherwise, the output is non-zero."],"metadata":{"id":"OPVYvUdoRoEc"}},{"cell_type":"code","source":["K = torch.tensor([[1.0, -1.0]])"],"metadata":{"id":"-sTlvv_IRpLL","executionInfo":{"status":"ok","timestamp":1642777968010,"user_tz":-480,"elapsed":20,"user":{"displayName":"Hanif Kukuh Raharjo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gict81qvzCzYor7OD2HAqOMscBAGuRrSJShYazDZg=s64","userId":"02100760507760735849"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["We are ready to perform the cross-correlation operation with arguments X (our input) and K (our kernel). As you can see, we detect 1 for the edge from white to black and -1 for the edge from black to white. All other outputs take value 0."],"metadata":{"id":"BLHdJbI-RwCt"}},{"cell_type":"code","source":["Y = corr2d(X, K)\n","Y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LjsR_E34Rw4F","outputId":"f745affd-c46f-48e5-fb0f-b55bf5111e89","executionInfo":{"status":"ok","timestamp":1642777968010,"user_tz":-480,"elapsed":20,"user":{"displayName":"Hanif Kukuh Raharjo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gict81qvzCzYor7OD2HAqOMscBAGuRrSJShYazDZg=s64","userId":"02100760507760735849"}}},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n","        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n","        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n","        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n","        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n","        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["We can now apply the kernel to the transposed image. As expected, it vanishes. The kernel K only detects vertical edges."],"metadata":{"id":"qgXAQnCiR6WE"}},{"cell_type":"code","source":["Z= X.t()\n","Z"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-xW0a48E5U1D","outputId":"b1472e5d-0893-4536-cfbf-073c41ba5451","executionInfo":{"status":"ok","timestamp":1642777968011,"user_tz":-480,"elapsed":19,"user":{"displayName":"Hanif Kukuh Raharjo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gict81qvzCzYor7OD2HAqOMscBAGuRrSJShYazDZg=s64","userId":"02100760507760735849"}}},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 1., 1., 1., 1., 1.],\n","        [1., 1., 1., 1., 1., 1.],\n","        [0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0.],\n","        [1., 1., 1., 1., 1., 1.],\n","        [1., 1., 1., 1., 1., 1.]])"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["corr2d(X.t(), K)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e-03s9FwR7Os","outputId":"889cefc6-44f0-4e3f-f648-9a63af017b8b","executionInfo":{"status":"ok","timestamp":1642777968012,"user_tz":-480,"elapsed":18,"user":{"displayName":"Hanif Kukuh Raharjo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gict81qvzCzYor7OD2HAqOMscBAGuRrSJShYazDZg=s64","userId":"02100760507760735849"}}},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0.]])"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["**6.2.4. Learning a Kernel**\n","\n","Now let us see whether we can learn the kernel that generated Y from X by looking at the input–output pairs only. \n","\n","1. We first construct a convolutional layer and initialize its kernel as a random tensor.\n","2. Next, in each iteration, we will use the squared error to compare Y with the output of the convolutional layer. \n","3. We can then calculate the gradient to update the kernel. \n","\n","For the sake of simplicity, in the following we use the built-in class for two-dimensional convolutional layers and ignore the bias."],"metadata":{"id":"I7kSZPEL6PsQ"}},{"cell_type":"code","source":["# Construct a two-dimensional convolutional layer with 1 output channel and a\n","# kernel of shape (1, 2). For the sake of simplicity, we ignore the bias here\n","\n","conv2d = nn.Conv2d(1,1, kernel_size=(1, 2), bias=False)\n","\n","# The two-dimensional convolutional layer uses four-dimensional input and\n","# output in the format of (example, channel, height, width), where the batch\n","# size (number of examples in the batch) and the number of channels are both 1\n","\n","X = X.reshape((1, 1, 6, 8))\n","Y = Y.reshape((1, 1, 6, 7))\n","lr = 3e-2  # Learning rate\n","\n","for i in range(10):\n","    Y_hat = conv2d(X)\n","    l = (Y_hat - Y) ** 2\n","    conv2d.zero_grad()\n","    l.sum().backward()\n","    # Update the kernel\n","    conv2d.weight.data[:] -= lr * conv2d.weight.grad\n","    if (i + 1) % 2 == 0:\n","        print(f'epoch {i + 1}, loss {l.sum():.3f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"clOv0TW-6j7M","outputId":"03d58c9e-38aa-492d-d2f0-4983dff806e1","executionInfo":{"status":"ok","timestamp":1642777968013,"user_tz":-480,"elapsed":17,"user":{"displayName":"Hanif Kukuh Raharjo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gict81qvzCzYor7OD2HAqOMscBAGuRrSJShYazDZg=s64","userId":"02100760507760735849"}}},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch 2, loss 10.367\n","epoch 4, loss 2.391\n","epoch 6, loss 0.668\n","epoch 8, loss 0.221\n","epoch 10, loss 0.082\n"]}]},{"cell_type":"code","source":["#Now we will take a look at the kernel tensor we learned.\n","\n","conv2d.weight.data.reshape((1, 2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9icd2vV96axT","outputId":"f4bc87b9-5d93-4047-c0f1-5fdd08cbd89d","executionInfo":{"status":"ok","timestamp":1642777968013,"user_tz":-480,"elapsed":15,"user":{"displayName":"Hanif Kukuh Raharjo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gict81qvzCzYor7OD2HAqOMscBAGuRrSJShYazDZg=s64","userId":"02100760507760735849"}}},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.9571, -1.0140]])"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["Indeed, the learned kernel tensor is remarkably close to the kernel tensor K we defined earlier."],"metadata":{"id":"C0D2WdMf7Qye"}},{"cell_type":"markdown","source":["6.2.5. Cross-Correlation and Convolution\n","6.2.6. Feature Map and Receptive Field\n","6.2.7. Summary"],"metadata":{"id":"-ZSeXIbo7WKt"}}]}