{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Padding and Stride.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#6.3. Padding and Stride\n","Source : https://d2l.ai/chapter_convolutional-neural-networks/padding-and-strides.html\n","\n","6.3.1. Padding\n","\n","In the following example, we create a two-dimensional convolutional layer with a height and width of 3 and apply 1 pixel of padding on all sides. Given an input with a height and width of 8, we find that the height and width of the output is also 8.\n"],"metadata":{"id":"cP1OBbsI72Sl"}},{"cell_type":"code","source":["!pip install d2l"],"metadata":{"id":"hQHnpIQO_8qg","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1642778037154,"user_tz":-480,"elapsed":23576,"user":{"displayName":"Hanif Kukuh Raharjo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gict81qvzCzYor7OD2HAqOMscBAGuRrSJShYazDZg=s64","userId":"02100760507760735849"}},"outputId":"af26970d-e97b-4e6b-db37-456114928a6e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting d2l\n","  Downloading d2l-0.17.3-py3-none-any.whl (82 kB)\n","\u001b[K     |████████████████████████████████| 82 kB 349 kB/s \n","\u001b[?25hRequirement already satisfied: jupyter==1.0.0 in /usr/local/lib/python3.7/dist-packages (from d2l) (1.0.0)\n","Collecting pandas==1.2.2\n","  Downloading pandas-1.2.2-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n","\u001b[K     |████████████████████████████████| 9.9 MB 29.2 MB/s \n","\u001b[?25hCollecting numpy==1.18.5\n","  Downloading numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n","\u001b[K     |████████████████████████████████| 20.1 MB 1.4 MB/s \n","\u001b[?25hCollecting matplotlib==3.3.3\n","  Downloading matplotlib-3.3.3-cp37-cp37m-manylinux1_x86_64.whl (11.6 MB)\n","\u001b[K     |████████████████████████████████| 11.6 MB 52.2 MB/s \n","\u001b[?25hCollecting requests==2.25.1\n","  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n","\u001b[K     |████████████████████████████████| 61 kB 8.9 MB/s \n","\u001b[?25hRequirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (7.6.5)\n","Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (5.2.2)\n","Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (5.2.0)\n","Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (5.3.1)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (4.10.1)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (5.6.1)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l) (7.1.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l) (1.3.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l) (3.0.6)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.2->d2l) (2018.9)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l) (2021.10.8)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l) (2.10)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib==3.3.3->d2l) (1.15.0)\n","Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.5.0)\n","Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.1.1)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.3.5)\n","Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.1.1)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (4.4.2)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (1.0.18)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (57.4.0)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (4.8.0)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (0.7.5)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (0.8.1)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (2.6.1)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (0.2.5)\n","Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (0.2.0)\n","Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (5.1.3)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (1.0.2)\n","Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (3.5.2)\n","Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (4.3.3)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (4.9.1)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (0.18.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (4.10.0)\n","Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (5.4.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (3.10.0.2)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (21.4.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (3.7.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l) (2.11.3)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l) (0.12.1)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l) (1.8.0)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter==1.0.0->d2l) (22.3.0)\n","Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter==1.0.0->d2l) (0.7.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter==1.0.0->d2l) (2.0.1)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (1.5.0)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.8.4)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.5.0)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (4.1.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.7.1)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.3)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter==1.0.0->d2l) (0.5.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter==1.0.0->d2l) (21.3)\n","Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter==1.0.0->d2l) (2.0.0)\n","Installing collected packages: numpy, requests, pandas, matplotlib, d2l\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.19.5\n","    Uninstalling numpy-1.19.5:\n","      Successfully uninstalled numpy-1.19.5\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: pandas\n","    Found existing installation: pandas 1.1.5\n","    Uninstalling pandas-1.1.5:\n","      Successfully uninstalled pandas-1.1.5\n","  Attempting uninstall: matplotlib\n","    Found existing installation: matplotlib 3.2.2\n","    Uninstalling matplotlib-3.2.2:\n","      Successfully uninstalled matplotlib-3.2.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 1.2.2 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.25.1 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed d2l-0.17.3 matplotlib-3.3.3 numpy-1.18.5 pandas-1.2.2 requests-2.25.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["matplotlib","mpl_toolkits","numpy","pandas"]}}},"metadata":{}}]},{"cell_type":"code","source":["import torch\n","from torch import nn\n","\n","\n","# We define a convenience function to calculate the convolutional layer. This\n","# function initializes the convolutional layer weights and performs\n","# corresponding dimensionality elevations and reductions on the input and\n","# output\n","def comp_conv2d(conv2d, X):\n","    # Here (1, 1) indicates that the batch size and the number of channels\n","    # are both 1\n","    X = X.reshape((1, 1) + X.shape)\n","    Y = conv2d(X)\n","    # Exclude the first two dimensions that do not interest us: examples and\n","    # channels\n","    return Y.reshape(Y.shape[2:])\n","# Note that here 1 row or column is padded on either side, so a total of 2\n","# rows or columns are added\n","conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1)\n","X = torch.rand(size=(8, 8))\n","comp_conv2d(conv2d, X).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I5VSuX7HAEwm","outputId":"a6ad0fca-1b04-4fb4-e375-be5a9e9a69a2","executionInfo":{"status":"ok","timestamp":1642778042495,"user_tz":-480,"elapsed":5346,"user":{"displayName":"Hanif Kukuh Raharjo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gict81qvzCzYor7OD2HAqOMscBAGuRrSJShYazDZg=s64","userId":"02100760507760735849"}}},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([8, 8])"]},"metadata":{},"execution_count":2}]},{"cell_type":"markdown","source":["When the height and width of the convolution kernel are different, we can make the output and input have the same height and width by setting different padding numbers for height and width."],"metadata":{"id":"lDayTK6dAU0b"}},{"cell_type":"code","source":["# Here, we use a convolution kernel with a height of 5 and a width of 3. The\n","# padding numbers on either side of the height and width are 2 and 1,\n","# respectively\n","conv2d = nn.Conv2d(1, 1, kernel_size=(5, 3), padding=(2, 1))\n","comp_conv2d(conv2d, X).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aead-MnwAV20","outputId":"9b838e06-2551-4074-e102-829c61dcb103","executionInfo":{"status":"ok","timestamp":1642778042496,"user_tz":-480,"elapsed":10,"user":{"displayName":"Hanif Kukuh Raharjo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gict81qvzCzYor7OD2HAqOMscBAGuRrSJShYazDZg=s64","userId":"02100760507760735849"}}},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([8, 8])"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["6.3.2. Stride\n","\n","Below, we set the strides on both the height and width to 2, thus halving the input height and width."],"metadata":{"id":"zbRUWh_6AamE"}},{"cell_type":"code","source":["conv2d = nn.Conv2d(1, 1, kernel_size=3, padding=1, stride=2)\n","comp_conv2d(conv2d, X).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5LgPcj8YAkEV","outputId":"c3258191-8827-42cc-c7f9-8574560c6161","executionInfo":{"status":"ok","timestamp":1642778042496,"user_tz":-480,"elapsed":8,"user":{"displayName":"Hanif Kukuh Raharjo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gict81qvzCzYor7OD2HAqOMscBAGuRrSJShYazDZg=s64","userId":"02100760507760735849"}}},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([4, 4])"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["#Next, we will look at a slightly more complicated example.\n","conv2d = nn.Conv2d(1, 1, kernel_size=(3, 5), padding=(0, 1), stride=(3, 4))\n","comp_conv2d(conv2d, X).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ytls-dnnApZ8","outputId":"5d92060b-2fd7-473d-fb5f-db60f6277d6b","executionInfo":{"status":"ok","timestamp":1642778042496,"user_tz":-480,"elapsed":6,"user":{"displayName":"Hanif Kukuh Raharjo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gict81qvzCzYor7OD2HAqOMscBAGuRrSJShYazDZg=s64","userId":"02100760507760735849"}}},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 2])"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["**6.3.3. Summary**\n","\n","1. Padding can increase the height and width of the output. This is often used to give the output the same height and width as the input.\n","\n","2. The stride can reduce the resolution of the output, for example reducing the height and width of the output to only  1/n  of the height and width of the input ( n  is an integer greater than  1 ).\n","\n","3. Padding and stride can be used to adjust the dimensionality of the data effectively."],"metadata":{"id":"D9WxvvsnA9Rr"}},{"cell_type":"markdown","source":["# 6.4. Multiple Input and Multiple Output Channels\n","\n","**6.4.1. Multiple Input Channel**s\n","\n","To make sure we really understand what is going on here, we can implement cross-correlation operations with multiple input channels ourselves. Notice that all we are doing is performing one cross-correlation operation per channel and then adding up the results."],"metadata":{"id":"dVg9QJXZBaM1"}},{"cell_type":"code","source":["import torch\n","from d2l import torch as d2l\n","\n","def corr2d_multi_in(X, K):\n","    # First, iterate through the 0th dimension (channel dimension) of `X` and\n","    # `K`. Then, add them together\n","    return sum(d2l.corr2d(x, k) for x, k in zip(X, K))"],"metadata":{"id":"9iMDEIcuBnvs","executionInfo":{"status":"ok","timestamp":1642778043268,"user_tz":-480,"elapsed":777,"user":{"displayName":"Hanif Kukuh Raharjo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gict81qvzCzYor7OD2HAqOMscBAGuRrSJShYazDZg=s64","userId":"02100760507760735849"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["We can construct the input tensor X and the kernel tensor K corresponding to the values in Fig. 6.4.1 to validate the output of the cross-correlation operation."],"metadata":{"id":"XsQLAhhLBsNr"}},{"cell_type":"code","source":["X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n","               [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n","K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])\n","\n","corr2d_multi_in(X, K)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aDiVR4kYBs_j","outputId":"eae5d8de-3a92-45f7-8d61-e180dd866b7a","executionInfo":{"status":"ok","timestamp":1642778043269,"user_tz":-480,"elapsed":21,"user":{"displayName":"Hanif Kukuh Raharjo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gict81qvzCzYor7OD2HAqOMscBAGuRrSJShYazDZg=s64","userId":"02100760507760735849"}}},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 56.,  72.],\n","        [104., 120.]])"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["**6.4.2. Multiple Output Channels**\n","\n","We implement a cross-correlation function to calculate the output of multiple channels as shown below."],"metadata":{"id":"jgX3dUKhBu0j"}},{"cell_type":"code","source":["def corr2d_multi_in_out(X, K):\n","    # Iterate through the 0th dimension of `K`, and each time, perform\n","    # cross-correlation operations with input `X`. All of the results are\n","    # stacked together\n","    return torch.stack([corr2d_multi_in(X, k) for k in K], 0)\n","    "],"metadata":{"id":"f1bibPrkB58d","executionInfo":{"status":"ok","timestamp":1642778043269,"user_tz":-480,"elapsed":20,"user":{"displayName":"Hanif Kukuh Raharjo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gict81qvzCzYor7OD2HAqOMscBAGuRrSJShYazDZg=s64","userId":"02100760507760735849"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["We construct a convolution kernel with 3 output channels by concatenating the kernel tensor K with K+1 (plus one for each element in K) and K+2."],"metadata":{"id":"3YiBTfecCBdV"}},{"cell_type":"code","source":["K = torch.stack((K, K + 1, K + 2), 0)\n","K.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HNFH8OhlCCR8","outputId":"b00fa5cf-716a-4bb1-e5bd-6c4966d5f096","executionInfo":{"status":"ok","timestamp":1642778043269,"user_tz":-480,"elapsed":20,"user":{"displayName":"Hanif Kukuh Raharjo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gict81qvzCzYor7OD2HAqOMscBAGuRrSJShYazDZg=s64","userId":"02100760507760735849"}}},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([3, 2, 2, 2])"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["Below, we perform cross-correlation operations on the input tensor X with the kernel tensor K. Now the output contains 3 channels. The result of the first channel is consistent with the result of the previous input tensor X and the multi-input channel, single-output channel kernel"],"metadata":{"id":"tREyd2S4CF_j"}},{"cell_type":"code","source":["corr2d_multi_in_out(X, K)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LtKJr8KxCKAj","outputId":"d3dfcc3e-bb12-4000-d2e2-55a3b3d7cd22","executionInfo":{"status":"ok","timestamp":1642778043270,"user_tz":-480,"elapsed":19,"user":{"displayName":"Hanif Kukuh Raharjo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gict81qvzCzYor7OD2HAqOMscBAGuRrSJShYazDZg=s64","userId":"02100760507760735849"}}},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[ 56.,  72.],\n","         [104., 120.]],\n","\n","        [[ 76., 100.],\n","         [148., 172.]],\n","\n","        [[ 96., 128.],\n","         [192., 224.]]])"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["**6.4.3.  1×1  Convolutional Layer**\n","\n","Let us check whether this works in practice: we implement a  1×1  convolution using a fully-connected layer. The only thing is that we need to make some adjustments to the data shape before and after the matrix multiplication."],"metadata":{"id":"OeT_RfyqCMtb"}},{"cell_type":"code","source":["def corr2d_multi_in_out_1x1(X, K):\n","    c_i, h, w = X.shape\n","    c_o = K.shape[0]\n","    X = X.reshape((c_i, h * w))\n","    K = K.reshape((c_o, c_i))\n","    # Matrix multiplication in the fully-connected layer\n","    Y = torch.matmul(K, X)\n","    return Y.reshape((c_o, h, w))"],"metadata":{"id":"zw2iEDGlCUNt","executionInfo":{"status":"ok","timestamp":1642778043270,"user_tz":-480,"elapsed":18,"user":{"displayName":"Hanif Kukuh Raharjo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gict81qvzCzYor7OD2HAqOMscBAGuRrSJShYazDZg=s64","userId":"02100760507760735849"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["When performing  1×1  convolution, the above function is equivalent to the previously implemented cross-correlation function corr2d_multi_in_out. Let us check this with some sample data."],"metadata":{"id":"OyUxwfswCWJd"}},{"cell_type":"code","source":["X = torch.normal(0, 1, (3, 3, 3))\n","K = torch.normal(0, 1, (2, 3, 1, 1))\n","\n","Y1 = corr2d_multi_in_out_1x1(X, K)\n","Y2 = corr2d_multi_in_out(X, K)\n","assert float(torch.abs(Y1 - Y2).sum()) < 1e-6"],"metadata":{"id":"y1KYCQoICYhk","executionInfo":{"status":"ok","timestamp":1642778043270,"user_tz":-480,"elapsed":17,"user":{"displayName":"Hanif Kukuh Raharjo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gict81qvzCzYor7OD2HAqOMscBAGuRrSJShYazDZg=s64","userId":"02100760507760735849"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["**6.4.4. Summary**\n","\n","\n","1. Multiple channels can be used to extend the model parameters of the convolutional layer.\n","\n","2. The  1×1  convolutional layer is equivalent to the fully-connected layer, when applied on a per pixel basis.\n","\n","3. The  1×1  convolutional layer is typically used to adjust the number of channels between network layers and to control model complexity."],"metadata":{"id":"tm3bfNHqCaP0"}},{"cell_type":"markdown","source":["#6.5. Pooling\n","\n","**6.5.1. Maximum Pooling and Average Pooling**\n","\n","In the code below, we implement the forward propagation of the pooling layer in the pool2d function. This function is similar to the corr2d function in Section 6.2. However, here we have no kernel, computing the output as either the maximum or the average of each region in the input."],"metadata":{"id":"h6acDS26C4fk"}},{"cell_type":"code","source":["import torch\n","from torch import nn\n","from d2l import torch as d2l\n","\n","def pool2d(X, pool_size, mode='max'):\n","    p_h, p_w = pool_size\n","    Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))\n","    for i in range(Y.shape[0]):\n","        for j in range(Y.shape[1]):\n","            if mode == 'max':\n","                Y[i, j] = X[i: i + p_h, j: j + p_w].max()\n","            elif mode == 'avg':\n","                Y[i, j] = X[i: i + p_h, j: j + p_w].mean()\n","    return Y"],"metadata":{"id":"Ou7bdXDjDDQW","executionInfo":{"status":"ok","timestamp":1642778043271,"user_tz":-480,"elapsed":18,"user":{"displayName":"Hanif Kukuh Raharjo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gict81qvzCzYor7OD2HAqOMscBAGuRrSJShYazDZg=s64","userId":"02100760507760735849"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["We can construct the input tensor X in Fig. 6.5.1 to validate the output of the two-dimensional maximum pooling layer."],"metadata":{"id":"Hq7GGiKwDD3U"}},{"cell_type":"code","source":["X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n","pool2d(X, (2, 2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"owQCqZ9hDGWz","outputId":"757a0d4e-b7b0-4e01-99fe-0d138b6ba188","executionInfo":{"status":"ok","timestamp":1642778043271,"user_tz":-480,"elapsed":18,"user":{"displayName":"Hanif Kukuh Raharjo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gict81qvzCzYor7OD2HAqOMscBAGuRrSJShYazDZg=s64","userId":"02100760507760735849"}}},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[4., 5.],\n","        [7., 8.]])"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["Also, we experiment with the average pooling layer."],"metadata":{"id":"Ky5N0gIYDIfs"}},{"cell_type":"code","source":["pool2d(X, (2, 2), 'avg')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h9EVmEwlDMwr","outputId":"719bb350-faf3-4123-e2cc-99beae593df7","executionInfo":{"status":"ok","timestamp":1642778043271,"user_tz":-480,"elapsed":15,"user":{"displayName":"Hanif Kukuh Raharjo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gict81qvzCzYor7OD2HAqOMscBAGuRrSJShYazDZg=s64","userId":"02100760507760735849"}}},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[2., 3.],\n","        [5., 6.]])"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["6.5.2. Padding and Stride\n","\n","As with convolutional layers, pooling layers can also change the output shape.And as before, we can alter the operation to achieve a desired output shape by padding the input and adjusting the stride. \n","\n","We can demonstrate the use of padding and strides in pooling layers via the built-in two-dimensional maximum pooling layer from the deep learning framework. \n","\n","We first construct an input tensor X whose shape has four dimensions, where the number of examples (batch size) and number of channels are both 1."],"metadata":{"id":"QBJJyQrfDRdD"}},{"cell_type":"code","source":["X = torch.arange(16, dtype=torch.float32).reshape((1, 1, 4, 4))\n","X"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HZlVc5WkDhvN","outputId":"4b1b7f70-e8a5-41e2-aa19-9e26f628b33f","executionInfo":{"status":"ok","timestamp":1642778043272,"user_tz":-480,"elapsed":15,"user":{"displayName":"Hanif Kukuh Raharjo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gict81qvzCzYor7OD2HAqOMscBAGuRrSJShYazDZg=s64","userId":"02100760507760735849"}}},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[[ 0.,  1.,  2.,  3.],\n","          [ 4.,  5.,  6.,  7.],\n","          [ 8.,  9., 10., 11.],\n","          [12., 13., 14., 15.]]]])"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["By default, the stride and the pooling window in the instance from the framework’s built-in class have the same shape. Below, we use a pooling window of shape (3, 3), so we get a stride shape of (3, 3) by default."],"metadata":{"id":"WV3ry8N5DiWV"}},{"cell_type":"code","source":["pool2d = nn.MaxPool2d(3)\n","pool2d(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SEwrmeVIDk1V","outputId":"d760e85d-974a-4fb7-c7c0-ffd6d0e931ac","executionInfo":{"status":"ok","timestamp":1642778043272,"user_tz":-480,"elapsed":14,"user":{"displayName":"Hanif Kukuh Raharjo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gict81qvzCzYor7OD2HAqOMscBAGuRrSJShYazDZg=s64","userId":"02100760507760735849"}}},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[[10.]]]])"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["#The stride and padding can be manually specified.\n","\n","pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n","pool2d(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zUFJ217_Dpc7","outputId":"efdf2e05-4702-4286-85ec-480fe98b2911","executionInfo":{"status":"ok","timestamp":1642778043272,"user_tz":-480,"elapsed":12,"user":{"displayName":"Hanif Kukuh Raharjo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gict81qvzCzYor7OD2HAqOMscBAGuRrSJShYazDZg=s64","userId":"02100760507760735849"}}},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[[ 5.,  7.],\n","          [13., 15.]]]])"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["#Of course, we can specify an arbitrary rectangular pooling window and specify the padding and stride for height and width, respectively.\n","\n","pool2d = nn.MaxPool2d((2, 3), stride=(2, 3), padding=(0, 1))\n","pool2d(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XCiAt-OlDuYV","outputId":"e979c7fc-0162-4a72-9845-e37d18a51260","executionInfo":{"status":"ok","timestamp":1642778043273,"user_tz":-480,"elapsed":12,"user":{"displayName":"Hanif Kukuh Raharjo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gict81qvzCzYor7OD2HAqOMscBAGuRrSJShYazDZg=s64","userId":"02100760507760735849"}}},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[[ 5.,  7.],\n","          [13., 15.]]]])"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["**6.5.3. Multiple Channels**\n","\n","When processing multi-channel input data, the pooling layer pools each input channel separately, rather than summing the inputs up over channels as in a convolutional layer. This means that the number of output channels for the pooling layer is the same as the number of input channels. \n","\n","Below, we will concatenate tensors X and X + 1 on the channel dimension to construct an input with 2 channels."],"metadata":{"id":"tdSeYfiZD2Fz"}},{"cell_type":"code","source":["X = torch.cat((X, X + 1), 1)\n","X"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GjSnnBb7D_BD","outputId":"19091553-6f6a-43bc-e884-87a678fc9636","executionInfo":{"status":"ok","timestamp":1642778043273,"user_tz":-480,"elapsed":11,"user":{"displayName":"Hanif Kukuh Raharjo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gict81qvzCzYor7OD2HAqOMscBAGuRrSJShYazDZg=s64","userId":"02100760507760735849"}}},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[[ 0.,  1.,  2.,  3.],\n","          [ 4.,  5.,  6.,  7.],\n","          [ 8.,  9., 10., 11.],\n","          [12., 13., 14., 15.]],\n","\n","         [[ 1.,  2.,  3.,  4.],\n","          [ 5.,  6.,  7.,  8.],\n","          [ 9., 10., 11., 12.],\n","          [13., 14., 15., 16.]]]])"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["As we can see, the number of output channels is still 2 after pooling."],"metadata":{"id":"XZVzkMQMEAHE"}},{"cell_type":"code","source":["pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n","pool2d(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vG0D8EJlECt1","outputId":"b8e983b5-4315-47b2-d24d-184ca530dffe","executionInfo":{"status":"ok","timestamp":1642778043273,"user_tz":-480,"elapsed":10,"user":{"displayName":"Hanif Kukuh Raharjo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gict81qvzCzYor7OD2HAqOMscBAGuRrSJShYazDZg=s64","userId":"02100760507760735849"}}},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[[ 5.,  7.],\n","          [13., 15.]],\n","\n","         [[ 6.,  8.],\n","          [14., 16.]]]])"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","source":["**6.5.4. Summary**\n","\n","Taking the input elements in the pooling window, the maximum pooling operation assigns the maximum value as the output and the average pooling operation assigns the average value as the output.\n","\n","One of the major benefits of a pooling layer is to alleviate the excessive sensitivity of the convolutional layer to location.\n","\n","We can specify the padding and stride for the pooling layer.\n","\n","Maximum pooling, combined with a stride larger than 1 can be used to reduce the spatial dimensions (e.g., width and height).\n","\n","The pooling layer’s number of output channels is the same as the number of input channels.\n"],"metadata":{"id":"mTU-WhyFEEoD"}}]}